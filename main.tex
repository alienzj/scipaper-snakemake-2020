\documentclass{scrartcl}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{authblk}
\usepackage[hidelinks]{hyperref}
\usepackage{xr}
\externaldocument{supplement.tex}

\usepackage[backend=biber]{biblatex}
\addbibresource{literature.bib}

\newcommand{\sharedfirst}{$\dagger$}
\newcommand{\sharedfirsttext}[1]{\affil[\sharedfirst]{#1}}
\newcommand{\corresponding}{*}
\newcommand{\correspondingtext}[1]{\affil[\corresponding]{#1}}
\newcommand{\image}[1]{\centering\includegraphics[width=\textwidth]{#1}}
\let\plainurl\url
\renewcommand{\url}[1]{\protect\plainurl{#1}}

\begin{document}

\author[1,2,\sharedfirst]{Felix Mölder}
\author[3,\sharedfirst]{Soo Lee}
\author[4,\sharedfirst]{Michael Hall}
\author[4,\sharedfirst]{Brice Letcher}
\author[5,\sharedfirst]{Vanessa Sochat}
\author[6,\sharedfirst]{Kim Philip Jablonski}
\author[1,7,\corresponding]{Johannes Köster}
\affil[1]{Algorithms for reproducible bioinformatics, Genome Informatics, Institute of Human Genetics, University Hospital Essen, University of Duisburg-Essen, Essen, Germany}
\affil[2]{Institute of Pathology, University Hospital Essen, University of Duisburg-Essen, Essen, Germany}
\affil[3]{Biomedical Informatics, Harvard Medical School, Harvard University, Boston, USA}
\affil[4]{EMBL-EBI}
\affil[5]{Stanford Computing, Stanford University}
\affil[6]{ETH Zürich}
\affil[7]{Medical Oncology, Harvard Medical School, Harvard University, Boston, USA}
\sharedfirsttext{Shared first author}
\correspondingtext{To whom correspondence should be addressed}

\title{Sustainable data analysis with Snakemake}
\maketitle

\begin{abstract}
	% abstract text
\end{abstract}

Performing data analysis has become ubiquitous across scientific disciplines.
Along with that, securing data analysis reproducibility has been identified as a major challenge~\parencite{Mesirov2010,Baker2016,Munaf__2017}.
In consequence, recent years have seen a wide adoption of scientific workflow management systems by the community.
Countless workflow management systems have been published (see~\url{https://github.com/pditommaso/awesome-pipeline}).
Roughly spoken, these can be partitioned into four niches, for which we will highlight the major representatives below.~ 

First, workflow management systems like Galaxy~\parencite{Afgan2018} offer a graphical user interface for composition and execution of workflows.
The obvious advantage is the shallow learning curve, making such systems accessible for everybody, without the need for programming skills.

Second, with systems like Anduril~\parencite{Cervera2019}, Balsam~\parencite{papka2018}, Hyperloom~\parencite{cima2018hyperloom}, Jug~\parencite{Coelho_2017}, Pwrake~\parencite{Tanaka_2010}, Ruffus~\parencite{Goodstadt2010}, SciPipe~\parencite{Lampa2019}, SCOOP \parencite{SCOOP_XSEDE2014}, and COMPSs~\parencite{Lordan_2013} workflows are specified using~ a set of classes and functions for generic programming languages like Python, Scala and others.
Such systems have the advantage that they can be used without a graphical interface (e.g. in a server environment), and that workflows can be straighforwardly managed with version control systems like Git (\url{https://git-scm.com}).~ 

Third, with systems like Nextflow~\parencite{Di_Tommaso_2017}, Snakemake~\parencite{Köster2012}, BioQueue~\parencite{Yao2017}, Bpipe~\parencite{Sadedin2012}, ClusterFlow~\parencite{Ewels2016}, Cylc~\parencite{J_Oliver_2018},~and BigDataScript~\parencite{Cingolani_2014}, workflows are specified using a domain specific language (DSL).
Here, the advantages of the second niche are shared, while adding the additional benefit of improved readability since the DSL provides statements and declarations that specifically model central components of workflow management, thereby obviating superfluous operators or boilerplate code.
In case of Nextflow and Snakemake, where the DSL is implemented as an extension to a generic programming language (Groovy and Python), even access to the full power of the underlying programming language is maintained (e.g. for implementing conditional execution and handling configuration).

Fourth, with systems like Popper~\parencite{Jimenez_2017}, workflow specification happens in a purely declarative way via configuration file formats like YAML.
Here, most of the benefits of the third niche are shared.
In addition, workflow specification can be particularly readable for non developers.
This comes however wit the downside of being more restricted since the facilities of imperative or functional programming are not available.

Fifth, there are system-independent workflow specification languages like CWL~\parencite{cwl} and WDL~\parencite{voss_full-stack_2017}.
These define a (declarative) syntax for specifying workflows, which can be parsed and executed by arbitrary executors, e.g. Cromwell (\url{https://cromwell.readthedocs.io}), Toil~\parencite{Vivian_2017} and Tibanna~\parencite{Lee_2019}.
Here, a main advantage is that the same workflow definition can be executed on various specialized execution backends, thereby promising scalability to virtually any computing platform.

Today, several of the above mentioned systems support full in silico reproducibility of data analyses (e.g. Galaxy, Nextflow, Snakemake, WDL, CWL), via allowing the definition and automatic scalable execution of each involved step, together with the ability to define and automatically deploy the software stack needed for each step (e.g. via the Conda package manager,~\url{https://docs.conda.io}, or Docker containers~\url{https://www.docker.com}).

Reproducibility is important to generate trust in scientific results.
However, we postulate that a truly sustainable data analysis needs to consider a full hierarchy of interdependent aspects (see Fig.~\ref{fig:sustainability}).

\begin{figure}
	\image{sustainability-in-wms.pdf}
	\caption{
		Hierarchy of aspects to consider for sustainable data analysis.
		By supporting the top layer, a workflow management system can promote the center layer, and thereby help to obtain true sustainability.
	}\label{fig:sustainability}
\end{figure}

By being \emph{automated}, \emph{scalable} to various computational platforms and levels of parallelism, and \emph{portable}, in the sense that it is able to be automatically deployed with all required software in exactly the needed versions, a data analysis gains full in silico \emph{reproducibility.
}

While being able to reproduce results is a major achievement, \emph{transparency} is equally important: the validity of results can only be fully assessed if~the parameters, software and custom code of each analysis step is fully accessible.
On the level of the code, a data analysis therefore has to be \emph{readable} and well \emph{documented}.
On the level of the results it has to be possible to \emph{trace} parameters, software stack and code through all involved steps.

Finally, valid results yielded from a reproducible data analysis become even more beneficial for the scientific community once the analysis can be reused for other projects.
In practice, this will almost never be a plain reuse, and instead requires~\emph{adaptability} to new circumstances, e.g. being able to extend the analysis, replace or modify steps and adjust parameter choices.
Such adaptability can only be achieved if the data analysis can easily be executed at a different computational environment (e.g. a different institute), thus it has to be \emph{scalable} and \emph{portable} again.
In addition, it is crucial that the analysis code is as \emph{readable} as possible such that it can be easily modified.

In this work, we show how sustainability in terms of these aspects is supported by Snakemake.
Since its original publication in 2012, Snakemake has gained a wide adoption, culminating in, on average, nowadays more than 3 new citations per week, and over 600 citations in total (Fig.~\ref{fig:citations}), making it one of the most widely used workflow management systems in science.

\begin{figure}
	\image{citations.pdf}
	\caption{
		Citations of the original Snakemake article, (a) by year, (b) by scientific discipline of the citing article.
		Data source:~\url{https://badge.dimensions.ai/details/id/pub.1018944052}, 2020/05/20.
	}
	\label{fig:citations}
\end{figure}

We first present several central and novel contributions to the field implemented in Snakemake.
Second, we show how Snakemake comprehensively covers data analysis needs by introducing generic workflow design patterns that can serve as blueprints for composing any kind of analysis.

\section{Results}

\printbibliography
\end{document}